Minimum Requirements:
- OpenAPI compatible api calling for llm
- Async fastAPI server deployed to GCP
- Test performance

TODO:
- [ ] Set up CI/CD on GCP for cloud run
- [ ] Build llm wrapper with fastAPI
- [ ] Test performance
- [ ] Prompt tune
