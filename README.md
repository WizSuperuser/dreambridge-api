Minimum Requirements:
- OpenAPI compatible api calling for llm
- Async fastAPI server deployed to GCP
- Test performance

TODO:
- [x] Set up CD on GCP for cloud run
- [ ] Add unauthenticated CORS for iteration
- [ ] Build llm wrapper with fastAPI
- [ ] Setup testing and CI
- [ ] deploy database for conversation history
- [ ] Add CORS and auth
- [ ] add logging and monitoring
- [ ] Test performance
- [ ] Prompt tune
- [ ] Performance tune with caching
